{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HDFS (Hadoop Distributed Storage system)\n",
    "- Designed for batch processing to work closely with MapReduce\n",
    "- Can handle over a petabyte\n",
    "- Written in Java & runs on commodity hardware\n",
    "- Data is organized in files & directories & is processed sequentially from the database\n",
    "- Multi-threaded system\n",
    "- Handshake with NameNode on startup\n",
    "    - Ensures correct namespace an version\n",
    "- Files are stored as collection of data blocks\n",
    "- Data block is represented by two files\n",
    "    - One containing data itself\n",
    "    - Other containing metadata like checksum\n",
    "- Secondary NameNode\n",
    "    - Cannot take over the NameNode\n",
    "    - Maintains namespace impage from transaction log\n",
    "    - Used to recover NameNode on reboot\n",
    "- HDFS Client\n",
    "    - Provides API to read/write/delete file\n",
    "        - READ: Get list of data nodes from NameNode then read data directly from Data Nodes\n",
    "        - WRITE: ...\n",
    "- NameNode ensures data isn't over or under-replicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intended to simplify the processing of vast amounts of data in parallel\n",
    "- Provides clean abstraction for programmers\n",
    "    - Written in Java\n",
    "    - Can be written in other languages using \"Hadoop Streaming\"\n",
    "- Job Tracker:\n",
    "    - Master componenet for scheduling and managing jobs and cluster resources\n",
    "- Task Trackers:\n",
    "    -...\n",
    "- Map:\n",
    "    - A list of data elements are passed one at a time to map() functions\n",
    "    - map() transform each data element to an individual output data element\n",
    "    - A map() produces one or more intermediate key-value pairs\n",
    "    - Mapper must receive data in key-value pairs\n",
    "    - Each mapper will receive one or more key-value pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See slides for visual examples on Map, Shuffle & Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sudo jps\n",
    "    - if namenode and datanode is running - HDFS is running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See comments on \"Hadoop Workshop.PDF\" for notes on the walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get WinSCP for file sharing between local os and VM if needed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
