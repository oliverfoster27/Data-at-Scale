{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing tool on top of hadoop system\n",
    "- PigLatin Script language\n",
    "- high-level dataflow system\n",
    "- Provides abstraction over MapReduce\n",
    "- A took used with Hadoop to analyze ver large datasets representing them as data flows\n",
    "- To write data analysis programs, Pig provides a high-level language known as Pig Latin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do I need pig?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you are not a programmer & don't want to write in Java or Python to control MapReduce\n",
    "- Pig was designed for perfomring a long series of data operations, making it ideal for three categories of big data jobs:\n",
    "    - ETL data pipelines\n",
    "    - Research on raw data\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Close to SQL\n",
    "- Pig can be invoked by other languages\n",
    "- Pig is extensible and supports User Defined Functions (UDF)\n",
    "    - UDFs can be created in other programming languages such as Java and invoked in Pig Scripts\n",
    "- Can analyze many types of data and stores in HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pig = Pig Latin + Pig Enginer\n",
    "- Pig Latin: dataflow language similar to SQL\n",
    "- Pig Engine: Accepts the Pig Latin scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pig Script -> Pig Execution Engine -> MapReduce -> Hadoop Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pig can be run locally or in MapReduce mode (default)\n",
    "    - MapReduce mode: ensure you have access to HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pig Latin Walkthrough:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open Pig Locally in Terminal: pig -x local\n",
    "- books = load '/home/cloudera/pig/books.csv';\n",
    "- col0 = foreach books generate $0;\n",
    "- dump col0;\n",
    "- books = load '/home/cloudera/pig/books.csv' Using PigStorage (',');\n",
    "\n",
    "\n",
    "- books = load '/home/cloudera/pig/books.csv' Using PigStorage (',') as (book,author,title,published);\n",
    "- col1 = foreach books generate (book, author);\n",
    "- dump author;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
